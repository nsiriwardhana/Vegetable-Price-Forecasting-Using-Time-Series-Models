{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "513251c9-3ab6-427b-a3e9-bb8f5bd930b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for the page to load...\n",
      "\n",
      "üìÑ Processing report: Inflation in March 2025 - CCPI\n",
      "üìé PDF URL: https://www.cbsl.gov.lk/sites/default/files/cbslweb_documents/press/pr/press_20250328_inflation_in_march_2025_ccpi_e.pdf\n",
      "‚úÖ PDF downloaded: temp_report.pdf\n",
      "\n",
      "‚úÖ Extracted Data:\n",
      "Year     Month  CCPI       Date\n",
      "2024     March 196.7 2024/03/01\n",
      "2024     April 195.2 2024/04/01\n",
      "2024       May 194.1 2024/05/01\n",
      "2024      June 195.6 2024/06/01\n",
      "2024      July 194.7 2024/07/01\n",
      "2024    August 191.1 2024/08/01\n",
      "2024 September 190.9 2024/09/01\n",
      "2024   October 189.9 2024/10/01\n",
      "2024  November 189.4 2024/11/01\n",
      "2024  December 191.7 2024/12/01\n",
      "2025   January 192.6 2025/01/01\n",
      "2025  February 192.2 2025/02/01\n",
      "2025     March 191.6 2025/03/01\n",
      "\n",
      "‚úÖ Saved to cbsl_ccpi_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import requests\n",
    "import urllib3\n",
    "import time\n",
    "import fitz  # PyMuPDF\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "from pdf2image import convert_from_path\n",
    "import pytesseract\n",
    "\n",
    "# üîß Path to Tesseract\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "# üîß Disable SSL warnings\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "# WebDriver config\n",
    "chrome_driver_path = \"C:\\\\chromedriver-win64\\\\chromedriver.exe\"\n",
    "options = webdriver.ChromeOptions()\n",
    "options.headless = False\n",
    "driver = webdriver.Chrome(service=Service(chrome_driver_path), options=options)\n",
    "\n",
    "# Visit CBSL page\n",
    "url = \"https://www.cbsl.gov.lk/en/measures-of-consumer-price-inflation\"\n",
    "driver.get(url)\n",
    "print(\"Waiting for the page to load...\")\n",
    "time.sleep(5)\n",
    "\n",
    "# Get inflation report links\n",
    "inflation_links = WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_all_elements_located((By.PARTIAL_LINK_TEXT, \"Inflation\"))\n",
    ")\n",
    "\n",
    "# Use the latest report\n",
    "first_link = inflation_links[0]\n",
    "print(f\"\\nüìÑ Processing report: {first_link.text.strip()}\")\n",
    "first_link.click()\n",
    "time.sleep(3)\n",
    "\n",
    "# Find PDF link\n",
    "pdf_elements = WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_all_elements_located((By.XPATH, \"//a[contains(@href, '.pdf')]\"))\n",
    ")\n",
    "\n",
    "pdf_url = None\n",
    "for el in pdf_elements:\n",
    "    href = el.get_attribute(\"href\")\n",
    "    if \"inflation\" in href.lower() and \"ccpi\" in href.lower():\n",
    "        pdf_url = href\n",
    "        break\n",
    "\n",
    "if not pdf_url:\n",
    "    print(\"‚ùå No PDF link found.\")\n",
    "    driver.quit()\n",
    "    exit()\n",
    "\n",
    "print(f\"üìé PDF URL: {pdf_url}\")\n",
    "\n",
    "# Download PDF\n",
    "pdf_response = requests.get(pdf_url, verify=False)\n",
    "local_pdf_path = \"temp_report.pdf\"\n",
    "if pdf_response.status_code == 200:\n",
    "    with open(local_pdf_path, 'wb') as f:\n",
    "        f.write(pdf_response.content)\n",
    "    print(f\"‚úÖ PDF downloaded: {local_pdf_path}\")\n",
    "else:\n",
    "    print(\"‚ùå Failed to download PDF.\")\n",
    "    driver.quit()\n",
    "    exit()\n",
    "\n",
    "# Read page 2 text\n",
    "doc = fitz.open(local_pdf_path)\n",
    "page_text = doc[1].get_text() if len(doc) >= 2 else \"\"\n",
    "doc.close()\n",
    "\n",
    "if not page_text.strip():\n",
    "    print(\"‚ö†Ô∏è No extractable text. Using OCR...\")\n",
    "    images = convert_from_path(local_pdf_path, first_page=2, last_page=2)\n",
    "    if images:\n",
    "        page_text = pytesseract.image_to_string(images[0])\n",
    "\n",
    "os.remove(local_pdf_path)\n",
    "\n",
    "# Process lines to extract Year, Month, CCPI\n",
    "lines = [line.strip() for line in page_text.split('\\n') if line.strip()]\n",
    "current_year = \"\"\n",
    "data = []\n",
    "months = [\n",
    "    \"January\", \"February\", \"March\", \"April\", \"May\", \"June\",\n",
    "    \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"\n",
    "]\n",
    "\n",
    "i = 0\n",
    "while i < len(lines):\n",
    "    line = lines[i]\n",
    "    # Detect Year\n",
    "    year_match = re.match(r'20\\d{2}', line)\n",
    "    if year_match:\n",
    "        current_year = year_match.group()\n",
    "        i += 1\n",
    "        continue\n",
    "\n",
    "    # Detect Month + CCPI pattern\n",
    "    month_match = next((m for m in months if m in line), None)\n",
    "    if current_year and month_match:\n",
    "        # Try to find CCPI as a float after month\n",
    "        ccpi_match = re.search(rf\"{month_match}\\s+(\\d{{3}}\\.\\d)\", line)\n",
    "        if not ccpi_match and (i + 1 < len(lines)):\n",
    "            # Try in the next line\n",
    "            ccpi_match = re.match(r\"(\\d{3}\\.\\d)\", lines[i + 1])\n",
    "            if ccpi_match:\n",
    "                ccpi_value = ccpi_match.group(1)\n",
    "                data.append([current_year, month_match, ccpi_value])\n",
    "                i += 2\n",
    "                continue\n",
    "        elif ccpi_match:\n",
    "            ccpi_value = ccpi_match.group(1)\n",
    "            data.append([current_year, month_match, ccpi_value])\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "    i += 1\n",
    "\n",
    "# Filter from January 2024 onward\n",
    "filtered_data = [row for row in data if not (\n",
    "    int(row[0]) < 2024 or (row[0] == \"2024\" and months.index(row[1]) < months.index(\"January\"))\n",
    ")]\n",
    "\n",
    "# Save to CSV with Date column\n",
    "if filtered_data:\n",
    "    df = pd.DataFrame(filtered_data, columns=[\"Year\", \"Month\", \"CCPI\"])\n",
    "\n",
    "    # Create Date column\n",
    "    month_map = {\n",
    "        \"January\": \"01\", \"February\": \"02\", \"March\": \"03\", \"April\": \"04\",\n",
    "        \"May\": \"05\", \"June\": \"06\", \"July\": \"07\", \"August\": \"08\",\n",
    "        \"September\": \"09\", \"October\": \"10\", \"November\": \"11\", \"December\": \"12\"\n",
    "    }\n",
    "    df[\"Date\"] = df.apply(lambda row: f\"{row['Year']}/{month_map[row['Month']]}/01\", axis=1)\n",
    "\n",
    "    df.to_csv(\"cbsl_ccpi.csv\", index=False)\n",
    "    print(\"\\n‚úÖ Extracted Data:\")\n",
    "    print(df.to_string(index=False))\n",
    "    print(\"\\n‚úÖ Saved to cbsl_ccpi_cleaned.csv\")\n",
    "else:\n",
    "    print(\"‚ùå No valid CCPI data found.\")\n",
    "\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac17c65b-e4cb-45af-8266-318188aaf6d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7280798b-d278-4e57-93dd-a892068999cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.chrome.service import Service\n",
    "# from selenium.webdriver.common.by import By\n",
    "# from selenium.webdriver.support.ui import WebDriverWait\n",
    "# from selenium.webdriver.support import expected_conditions as EC\n",
    "# import requests\n",
    "# import urllib3\n",
    "# import time\n",
    "# import fitz  # PyMuPDF\n",
    "# import pandas as pd\n",
    "# import os\n",
    "# import re\n",
    "\n",
    "# # üîß Disable SSL warnings\n",
    "# urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "# # ChromeDriver path\n",
    "# chrome_driver_path = \"C:\\\\chromedriver-win64\\\\chromedriver.exe\"\n",
    "\n",
    "# # Set up WebDriver\n",
    "# options = webdriver.ChromeOptions()\n",
    "# options.headless = False  # Set True to run in background\n",
    "# driver = webdriver.Chrome(service=Service(chrome_driver_path), options=options)\n",
    "\n",
    "# # Go to CBSL inflation page\n",
    "# url = \"https://www.cbsl.gov.lk/en/measures-of-consumer-price-inflation\"\n",
    "# driver.get(url)\n",
    "# print(\"Waiting for the page to load...\")\n",
    "# time.sleep(5)\n",
    "\n",
    "# # Extract inflation-related links\n",
    "# print(\"Extracting links to monthly inflation reports...\")\n",
    "# inflation_links = WebDriverWait(driver, 10).until(\n",
    "#     EC.presence_of_all_elements_located((By.PARTIAL_LINK_TEXT, \"Inflation\"))\n",
    "# )\n",
    "\n",
    "# # Store extracted data\n",
    "# data = []\n",
    "\n",
    "# # Number of reports to extract\n",
    "# N = 5\n",
    "# for i in range(min(N, len(inflation_links))):\n",
    "#     try:\n",
    "#         # Re-fetch links to avoid stale element\n",
    "#         inflation_links = WebDriverWait(driver, 10).until(\n",
    "#             EC.presence_of_all_elements_located((By.PARTIAL_LINK_TEXT, \"Inflation\"))\n",
    "#         )\n",
    "#         link = inflation_links[i]\n",
    "#         report_title = link.text.strip()\n",
    "#         print(f\"\\nüìÑ Processing report: {report_title}\")\n",
    "\n",
    "#         link.click()\n",
    "#         time.sleep(3)\n",
    "\n",
    "#         # Get the correct PDF link\n",
    "#         pdf_elements = WebDriverWait(driver, 10).until(\n",
    "#             EC.presence_of_all_elements_located((By.XPATH, \"//a[contains(@href, '.pdf')]\"))\n",
    "#         )\n",
    "\n",
    "#         pdf_url = None\n",
    "#         for el in pdf_elements:\n",
    "#             href = el.get_attribute(\"href\")\n",
    "#             if \"inflation\" in href.lower() and \"ccpi\" in href.lower():\n",
    "#                 pdf_url = href\n",
    "#                 break\n",
    "\n",
    "#         if not pdf_url:\n",
    "#             print(\"‚ùå No valid inflation PDF found, skipping.\")\n",
    "#             driver.back()\n",
    "#             time.sleep(2)\n",
    "#             continue\n",
    "\n",
    "#         print(f\"üìé PDF URL: {pdf_url}\")\n",
    "\n",
    "#         # Download the PDF\n",
    "#         pdf_response = requests.get(pdf_url, verify=False)\n",
    "#         if pdf_response.status_code == 200:\n",
    "#             local_pdf_path = f\"temp_report_{i+1}.pdf\"\n",
    "#             with open(local_pdf_path, 'wb') as f:\n",
    "#                 f.write(pdf_response.content)\n",
    "#             print(f\"‚úÖ PDF downloaded: {local_pdf_path}\")\n",
    "\n",
    "#             # Extract PDF text\n",
    "#             doc = fitz.open(local_pdf_path)\n",
    "#             full_text = \"\"\n",
    "#             for page in doc:\n",
    "#                 full_text += page.get_text()\n",
    "#             doc.close()\n",
    "#             os.remove(local_pdf_path)\n",
    "\n",
    "#             # Extract information\n",
    "#             extracted_date = report_title\n",
    "#             index_value = \"\"\n",
    "\n",
    "#             # Search for \"Index Value\" followed by a number like 192.2\n",
    "#             match = re.search(r'Index Value[^0-9]*([\\d]+\\.\\d+)', full_text)\n",
    "#             if match:\n",
    "#                 index_value = match.group(1)\n",
    "#             else:\n",
    "#                 # fallback: look for something like 'CCPI (2021=100) recorded 192.2 points'\n",
    "#                 match_alt = re.search(r'CCPI\\s*\\(2021=100\\)[^\\d]*([\\d]+\\.\\d+)', full_text)\n",
    "#                 if match_alt:\n",
    "#                     index_value = match_alt.group(1)\n",
    "\n",
    "#             print(f\"üìå Extracted Index Value: {index_value}\")\n",
    "#             data.append([extracted_date, index_value])\n",
    "#         else:\n",
    "#             print(\"‚ùå Failed to download PDF.\")\n",
    "\n",
    "#         # Back to main page\n",
    "#         driver.back()\n",
    "#         time.sleep(2)\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"‚ö†Ô∏è Error: {e}\")\n",
    "#         continue\n",
    "\n",
    "# # Save to CSV\n",
    "# df = pd.DataFrame(data, columns=[\"Report Title\", \"Index Value\"])\n",
    "# csv_filename = \"cbsl_index_values.csv\"\n",
    "# df.to_csv(csv_filename, index=False)\n",
    "# print(f\"\\n‚úÖ Data saved to: {csv_filename}\")\n",
    "\n",
    "# # Quit browser\n",
    "# driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "635f01c0-975b-4a94-89e3-cafd40ab2a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.chrome.service import Service\n",
    "# from selenium.webdriver.common.by import By\n",
    "# from selenium.webdriver.support.ui import WebDriverWait\n",
    "# from selenium.webdriver.support import expected_conditions as EC\n",
    "# import requests\n",
    "# import urllib3\n",
    "# import time\n",
    "# import fitz  # PyMuPDF\n",
    "# import pandas as pd\n",
    "# import os\n",
    "# import re\n",
    "\n",
    "# # üîß Disable SSL warnings\n",
    "# urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "# # ChromeDriver path\n",
    "# chrome_driver_path = \"C:\\\\chromedriver-win64\\\\chromedriver.exe\"\n",
    "\n",
    "# # Set up WebDriver\n",
    "# options = webdriver.ChromeOptions()\n",
    "# options.headless = False  # Set True to run in background\n",
    "# driver = webdriver.Chrome(service=Service(chrome_driver_path), options=options)\n",
    "\n",
    "# # Target URL\n",
    "# base_url = \"https://www.cbsl.gov.lk/en/measures-of-consumer-price-inflation\"\n",
    "\n",
    "# # Store extracted data\n",
    "# data = []\n",
    "\n",
    "# # Loop control\n",
    "# processed_titles = set()\n",
    "# index = 0\n",
    "\n",
    "# while True:\n",
    "#     driver.get(base_url)\n",
    "#     print(\"\\nüîÑ Navigated to CBSL inflation page...\")\n",
    "#     time.sleep(5)\n",
    "\n",
    "#     # Extract updated inflation links\n",
    "#     inflation_links = WebDriverWait(driver, 10).until(\n",
    "#         EC.presence_of_all_elements_located((By.PARTIAL_LINK_TEXT, \"Inflation\"))\n",
    "#     )\n",
    "\n",
    "#     # Filter out already processed and < 2024 links\n",
    "#     links_filtered = []\n",
    "#     for link in inflation_links:\n",
    "#         title = link.text.strip()\n",
    "#         if title not in processed_titles and re.search(r\"20(2[4-9]|[3-9][0-9])\", title):  # year >= 2024\n",
    "#             links_filtered.append(link)\n",
    "\n",
    "#     # Check if done\n",
    "#     if index >= len(links_filtered):\n",
    "#         print(\"\\n‚úÖ All 2024+ inflation reports processed.\")\n",
    "#         break\n",
    "\n",
    "#     try:\n",
    "#         link = links_filtered[index]\n",
    "#         report_title = link.text.strip()\n",
    "#         processed_titles.add(report_title)\n",
    "\n",
    "#         print(f\"\\nüìÑ Processing report: {report_title}\")\n",
    "#         link.click()\n",
    "#         time.sleep(3)\n",
    "\n",
    "#         # Get the correct PDF link\n",
    "#         pdf_elements = WebDriverWait(driver, 10).until(\n",
    "#             EC.presence_of_all_elements_located((By.XPATH, \"//a[contains(@href, '.pdf')]\"))\n",
    "#         )\n",
    "\n",
    "#         pdf_url = None\n",
    "#         for el in pdf_elements:\n",
    "#             href = el.get_attribute(\"href\")\n",
    "#             if \"inflation\" in href.lower() and \"ccpi\" in href.lower():\n",
    "#                 pdf_url = href\n",
    "#                 break\n",
    "\n",
    "#         if not pdf_url:\n",
    "#             print(\"‚ùå No valid inflation PDF found, skipping.\")\n",
    "#             index += 1\n",
    "#             continue\n",
    "\n",
    "#         print(f\"üìé PDF URL: {pdf_url}\")\n",
    "\n",
    "#         # Download the PDF\n",
    "#         pdf_response = requests.get(pdf_url, verify=False)\n",
    "#         if pdf_response.status_code == 200:\n",
    "#             local_pdf_path = f\"temp_report_{index+1}.pdf\"\n",
    "#             with open(local_pdf_path, 'wb') as f:\n",
    "#                 f.write(pdf_response.content)\n",
    "#             print(f\"‚úÖ PDF downloaded: {local_pdf_path}\")\n",
    "\n",
    "#             # Extract PDF text\n",
    "#             doc = fitz.open(local_pdf_path)\n",
    "#             full_text = \"\"\n",
    "#             for page in doc:\n",
    "#                 full_text += page.get_text()\n",
    "#             doc.close()\n",
    "#             os.remove(local_pdf_path)\n",
    "\n",
    "#             # Extract information\n",
    "#             index_value = \"\"\n",
    "\n",
    "#             match = re.search(r'Index Value[^0-9]*([\\d]+\\.\\d+)', full_text)\n",
    "#             if match:\n",
    "#                 index_value = match.group(1)\n",
    "#             else:\n",
    "#                 match_alt = re.search(r'CCPI\\s*\\(2021=100\\)[^\\d]*([\\d]+\\.\\d+)', full_text)\n",
    "#                 if match_alt:\n",
    "#                     index_value = match_alt.group(1)\n",
    "\n",
    "#             print(f\"üìå Extracted Index Value: {index_value}\")\n",
    "#             data.append([report_title, index_value])\n",
    "#         else:\n",
    "#             print(\"‚ùå Failed to download PDF.\")\n",
    "\n",
    "#         index += 1\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"‚ö†Ô∏è Error: {e}\")\n",
    "#         index += 1\n",
    "#         continue\n",
    "\n",
    "# # Save to CSV\n",
    "# df = pd.DataFrame(data, columns=[\"Report Title\", \"Index Value\"])\n",
    "# csv_filename = \"cbsl_index_values.csv\"\n",
    "# df.to_csv(csv_filename, index=False)\n",
    "# print(f\"\\n‚úÖ Data saved to: {csv_filename}\")\n",
    "\n",
    "# driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2f0738-dada-4f46-a5f2-2d4c2a022158",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d15d7d-af6e-4eac-8c1c-b90d2b01cc95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a45a1b-35b8-4abb-a4ff-d64e8d35bf83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1278959-b023-4ec4-89be-ec95ec226f3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "169ad42e-ef38-4258-9f62-93e25feb1936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.chrome.service import Service\n",
    "# from selenium.webdriver.common.by import By\n",
    "# from selenium.webdriver.support.ui import WebDriverWait\n",
    "# from selenium.webdriver.support import expected_conditions as EC\n",
    "# import requests\n",
    "# import urllib3\n",
    "# import time\n",
    "# import fitz  # PyMuPDF\n",
    "# import pandas as pd\n",
    "# import os\n",
    "# import re\n",
    "\n",
    "# from pdf2image import convert_from_path\n",
    "# import pytesseract\n",
    "\n",
    "# # üîß Path to Tesseract\n",
    "# pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "# # üîß Disable SSL warnings\n",
    "# urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "# # WebDriver config\n",
    "# chrome_driver_path = \"C:\\\\chromedriver-win64\\\\chromedriver.exe\"\n",
    "# options = webdriver.ChromeOptions()\n",
    "# options.headless = False\n",
    "# driver = webdriver.Chrome(service=Service(chrome_driver_path), options=options)\n",
    "\n",
    "# # Visit CBSL page\n",
    "# url = \"https://www.cbsl.gov.lk/en/measures-of-consumer-price-inflation\"\n",
    "# driver.get(url)\n",
    "# print(\"Waiting for the page to load...\")\n",
    "# time.sleep(5)\n",
    "\n",
    "# # Get inflation report links\n",
    "# inflation_links = WebDriverWait(driver, 10).until(\n",
    "#     EC.presence_of_all_elements_located((By.PARTIAL_LINK_TEXT, \"Inflation\"))\n",
    "# )\n",
    "\n",
    "# # Use the latest report\n",
    "# first_link = inflation_links[0]\n",
    "# print(f\"\\nüìÑ Processing report: {first_link.text.strip()}\")\n",
    "# first_link.click()\n",
    "# time.sleep(3)\n",
    "\n",
    "# # Find PDF link\n",
    "# pdf_elements = WebDriverWait(driver, 10).until(\n",
    "#     EC.presence_of_all_elements_located((By.XPATH, \"//a[contains(@href, '.pdf')]\"))\n",
    "# )\n",
    "\n",
    "# pdf_url = None\n",
    "# for el in pdf_elements:\n",
    "#     href = el.get_attribute(\"href\")\n",
    "#     if \"inflation\" in href.lower() and \"ccpi\" in href.lower():\n",
    "#         pdf_url = href\n",
    "#         break\n",
    "\n",
    "# if not pdf_url:\n",
    "#     print(\"‚ùå No PDF link found.\")\n",
    "#     driver.quit()\n",
    "#     exit()\n",
    "\n",
    "# print(f\"üìé PDF URL: {pdf_url}\")\n",
    "\n",
    "# # Download PDF\n",
    "# pdf_response = requests.get(pdf_url, verify=False)\n",
    "# local_pdf_path = \"temp_report.pdf\"\n",
    "# if pdf_response.status_code == 200:\n",
    "#     with open(local_pdf_path, 'wb') as f:\n",
    "#         f.write(pdf_response.content)\n",
    "#     print(f\"‚úÖ PDF downloaded: {local_pdf_path}\")\n",
    "# else:\n",
    "#     print(\"‚ùå Failed to download PDF.\")\n",
    "#     driver.quit()\n",
    "#     exit()\n",
    "\n",
    "# # Read page 2 text\n",
    "# doc = fitz.open(local_pdf_path)\n",
    "# page_text = doc[1].get_text() if len(doc) >= 2 else \"\"\n",
    "# doc.close()\n",
    "\n",
    "# if not page_text.strip():\n",
    "#     print(\"‚ö†Ô∏è No extractable text. Using OCR...\")\n",
    "#     images = convert_from_path(local_pdf_path, first_page=2, last_page=2)\n",
    "#     if images:\n",
    "#         page_text = pytesseract.image_to_string(images[0])\n",
    "\n",
    "# os.remove(local_pdf_path)\n",
    "\n",
    "# # print(\"\\nüìù Raw Extracted Text:\\n\", page_text)\n",
    "\n",
    "# # Process lines to extract Year, Month, CCPI\n",
    "# lines = [line.strip() for line in page_text.split('\\n') if line.strip()]\n",
    "# current_year = \"\"\n",
    "# data = []\n",
    "# months = [\n",
    "#     \"January\", \"February\", \"March\", \"April\", \"May\", \"June\",\n",
    "#     \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"\n",
    "# ]\n",
    "\n",
    "# i = 0\n",
    "# while i < len(lines):\n",
    "#     line = lines[i]\n",
    "#     # Detect Year\n",
    "#     year_match = re.match(r'20\\d{2}', line)\n",
    "#     if year_match:\n",
    "#         current_year = year_match.group()\n",
    "#         i += 1\n",
    "#         continue\n",
    "\n",
    "#     # Detect Month + CCPI pattern\n",
    "#     month_match = next((m for m in months if m in line), None)\n",
    "#     if current_year and month_match:\n",
    "#         # Try to find CCPI as a float after month\n",
    "#         ccpi_match = re.search(rf\"{month_match}\\s+(\\d{{3}}\\.\\d)\", line)\n",
    "#         if not ccpi_match and (i + 1 < len(lines)):\n",
    "#             # Try in the next line\n",
    "#             ccpi_match = re.match(r\"(\\d{3}\\.\\d)\", lines[i + 1])\n",
    "#             if ccpi_match:\n",
    "#                 ccpi_value = ccpi_match.group(1)\n",
    "#                 data.append([current_year, month_match, ccpi_value])\n",
    "#                 i += 2\n",
    "#                 continue\n",
    "#         elif ccpi_match:\n",
    "#             ccpi_value = ccpi_match.group(1)\n",
    "#             data.append([current_year, month_match, ccpi_value])\n",
    "#             i += 1\n",
    "#             continue\n",
    "\n",
    "#     i += 1\n",
    "\n",
    "# # Save to CSV\n",
    "# if data:\n",
    "#     df = pd.DataFrame(data, columns=[\"Year\", \"Month\", \"CCPI\"])\n",
    "#     df.to_csv(\"cbsl_ccpi_cleaned.csv\", index=False)\n",
    "#     print(\"\\n‚úÖ Extracted Data:\")\n",
    "#     print(df.to_string(index=False))\n",
    "#     print(\"\\n‚úÖ Saved to cbsl_ccpi.csv\")\n",
    "# else:\n",
    "#     print(\"‚ùå No valid CCPI data found.\")\n",
    "\n",
    "# driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0749c1-9993-44ba-93b5-0940b67966f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3f1672-0e99-4a6e-8717-b2223003276c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
